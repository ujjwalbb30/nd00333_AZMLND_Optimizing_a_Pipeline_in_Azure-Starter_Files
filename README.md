# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
This dataset contains the data about different characteristics of customers of a bank (e.g. marital status, job specification, age, previous loan, defaulting status, education qualifications etc.) and we seek to predict wheather a customer applied for a fixed term deposit.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best performing model was a Logistic Regression model with parameter value of C (Inverse of Regularization strength) and max_iter (Maximum number of iterations taken for the solvers to converge) as '0.6065569080865363' and '200' respectively. It performed with an accuracy of 0.9108883575501195.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The pipeline is created using HyperDriveConfig which requires an estimator, an early termination policy, a parameter sampler, a primary metric name, a primary metric goal and a value for maximum total runs. A parameter sampler is created using RandomParameterSampling which generates a set values of C and max_iter (equal to value of maximum total runs) to be used in child runs of experiment. For C, a continuous set of values ranging from 0.0005 to 1.0 is used and for max_iter, a discrete set of values is used which includes 50,100,150,200 and 250. BanditPolicy is used as early termination policy with evalution_interval as 5, slack_amount as 0.2 and delay_evalution as 5. This means if Run X is the currently best performing run with an accuracy of 0.9 after 5 intervals, then any run with an accuracy less than 0.7 (0.9 - 0.2) after 5 iterations will be terminated, and the delay_evaluation will delay the first termination policy evaluation for 5 sequences. An SKLearn estimator is used with train.py as training script for Scikit-Learn experiments which trains a Logistic Regression model on bank data (in which the characteristics are converted to numerical values with the help of clean data function defined in train.py which uses one hot encoding method) with varying sets of values of C and max_iter supplied by the parameter sampler (RandomParameterSampling in our case).

**What are the benefits of the parameter sampler you chose?**
The parameter sampler chosen is RandomParameterSampling which selects hyperparameter values randomly from the defined search space. RandomParameterSampling results in good results without consuming too much time.

**What are the benefits of the early stopping policy you chose?**
The early stopping policy chosen is BanditPolicy with evalution_interval as 5, slack_amount as 0.2 and delay_evalution as 5. This means if Run X is the currently best performing run with an accuracy of 0.9 after 5 intervals, then any run with an accuracy less than 0.7 (0.9 - 0.2) after 5 iterations will be terminated, and the delay_evaluation will delay the first termination policy evaluation for 5 sequences. This means I will not lose promising jobs and also the jobs with poor perfromance will be terminated early hence saving computation time and costs.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
AutoML is configured through AutoMLConfig with experiment_timeout_minutes being 30 minutes ( i.e. the AutoML run will close after 30 minutes if not terminated beforehand ) , task being 'classification', primary_metric being 'accuracy', training_data being the whole dataset including 'features' and 'labels', label_column_name being the name of label column and n_cross_validations being 5 (i.e. the dataset will be split into 5 different dataset for cross validation purposes in order to make our model more confident). AutoML ran 27 iterations which resulted in VotingEnsemble pipeline as the best one with metric score ( i.e. accuracy) equals 0.9167. 

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
